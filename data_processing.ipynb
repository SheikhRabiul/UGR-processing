{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Select Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "threshold1 = 13000000\n",
    "threshold2 = 1000\n",
    "\n",
    "Normal traffic:\n",
    "             DateTime\n",
    "2016-03-18  10           402909\n",
    "            11          3290391\n",
    "            12          3391740\n",
    "            13          3348730\n",
    "            14          2566230\n",
    "Name: Label, dtype: int64\n",
    "\n",
    "Abnormal traffic:\n",
    "             DateTime\n",
    "2016-03-18  10           21\n",
    "            11          567\n",
    "            12          348\n",
    "            13          987\n",
    "            14           77\n",
    "            18            1\n",
    "            19            9\n",
    "Name: Label, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "threshold1 = 70000000\n",
    "threshold2 = 10000\n",
    "\n",
    "2016-03-18  10 -> 2016-03-19  9\n",
    "\n",
    "\n",
    "## Select the first 24h:\n",
    "\\# of normal traffic:  63337682\n",
    "\n",
    "\\# of blacklist traffic:  12005\n",
    "\n",
    "\\# of spam traffic:  16166\n",
    "\n",
    "\\# of ssh scan traffic:  15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select by number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of normal traffic:  70000000\n",
      "# of blacklist traffic:  100000\n",
      "# of spam traffic:  100000\n",
      "# of ssh scan traffic:  15\n",
      "Done!\n",
      "# of blacklist (skipped) in the normal traffic:  303970\n"
     ]
    }
   ],
   "source": [
    "threshold1 = 70000000\n",
    "threshold2 = 100000\n",
    "\n",
    "#normal = True\n",
    "input_file = \"./UGRdata/uniq/march.week3.csv.uniqblacklistremoved\"\n",
    "input_b_file = \"./UGRdata/uniq/blacklist_flows_cut.csv\"\n",
    "input_sp_file = \"./UGRdata/uniq/spam_flows_cut.csv\"\n",
    "input_ssh_file = \"./UGRdata/uniq/sshscan_flows_cut.csv\"\n",
    "\n",
    "\n",
    "output_file = \"./UGRdata/parsed/selected_70m_blacklist_100.csv\"\n",
    "\n",
    "\n",
    "count1 = 0\n",
    "\n",
    "header ='DateTime,FlowDuration,SrcIP,DstIP,SrcPort,DstPort,Protocol,Flag,ForwardingStatus,TypeofService,PacketExed,Bytes,TrafficType,Label'\n",
    "\n",
    "with open(output_file, \"w\") as outfile:\n",
    "    outfile.write(header)\n",
    "    outfile.write(\"\\n\")\n",
    "    #select normal traffic\n",
    "    with open(input_file) as infile:\n",
    "        count = 0\n",
    "        for line in infile:\n",
    "            if line.strip() == \"\":\n",
    "                continue\n",
    "                \n",
    "            if count < threshold1:\n",
    "                if \"blacklist\" in line:\n",
    "                    #print(line)\n",
    "                    count1 += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    outfile.write(''.join([line.strip(), ',normal', '\\n']))\n",
    "                    count += 1\n",
    "            else:\n",
    "                #print(\"# of normal traffic: \", count)\n",
    "                break\n",
    "        print(\"# of normal traffic: \", count)\n",
    "    \n",
    "    #select blacklist traffic\n",
    "    with open(input_b_file) as b_infile:\n",
    "        count_b = 0\n",
    "        for line in b_infile:\n",
    "            if count_b < threshold2:\n",
    "                if \"blacklist\" in line:\n",
    "                    outfile.write(''.join([line.strip(), ',abnormal', '\\n']))\n",
    "                    count_b += 1\n",
    "            else:\n",
    "                break\n",
    "        print(\"# of blacklist traffic: \", count_b)\n",
    "        \n",
    "    #select spam traffic\n",
    "    with open(input_sp_file) as b_infile:\n",
    "        count_b = 0\n",
    "        for line in b_infile:\n",
    "            if count_b < threshold2:\n",
    "                if \"spam\" in line:\n",
    "                    outfile.write(''.join([line.strip(), ',abnormal', '\\n']))\n",
    "                    count_b += 1\n",
    "            else:\n",
    "                break\n",
    "        print(\"# of spam traffic: \", count_b)\n",
    "        \n",
    "    #select ssh scan traffic\n",
    "    with open(input_ssh_file) as b_infile:\n",
    "        count_b = 0\n",
    "        for line in b_infile:\n",
    "            if count_b < threshold2:\n",
    "                if \"sshscan\" in line:\n",
    "                    outfile.write(''.join([line.strip(), ',abnormal', '\\n']))\n",
    "                    count_b += 1\n",
    "            else:\n",
    "                break\n",
    "        print(\"# of ssh scan traffic: \", count_b)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Done!\")\n",
    "print(\"# of blacklist (skipped) in the normal traffic: \", count1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select by hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of normal traffic:  63337682\n",
      "# of blacklist traffic:  12005\n",
      "# of spam traffic:  16166\n",
      "# of ssh scan traffic:  15\n",
      "Done!\n",
      "# of blacklist (skipped) in the normal traffic:  286930\n"
     ]
    }
   ],
   "source": [
    "threshold1 = 70000000\n",
    "threshold2 = 200000\n",
    "\n",
    "#normal = True\n",
    "input_file = \"./UGRdata/uniq/march.week3.csv.uniqblacklistremoved\"\n",
    "input_b_file = \"./UGRdata/uniq/blacklist_flows_cut.csv\"\n",
    "input_sp_file = \"./UGRdata/uniq/spam_flows_cut.csv\"\n",
    "input_ssh_file = \"./UGRdata/uniq/sshscan_flows_cut.csv\"\n",
    "\n",
    "\n",
    "output_file = \"./UGRdata/parsed/selected_24h.csv\"\n",
    "\n",
    "\n",
    "count1 = 0\n",
    "\n",
    "header ='DateTime,FlowDuration,SrcIP,DstIP,SrcPort,DstPort,Protocol,Flag,ForwardingStatus,TypeofService,PacketExed,Bytes,TrafficType,Label'\n",
    "\n",
    "with open(output_file, \"w\") as outfile:\n",
    "    outfile.write(header)\n",
    "    outfile.write(\"\\n\")\n",
    "    #select normal traffic\n",
    "    with open(input_file) as infile:\n",
    "        count = 0\n",
    "        for line in infile:\n",
    "            if line.strip() == \"\":\n",
    "                continue\n",
    "            \n",
    "            if '2016-03-19 10:' in line:\n",
    "                break\n",
    "                \n",
    "            if count < threshold1:\n",
    "                if \"blacklist\" in line:\n",
    "                    #print(line)\n",
    "                    count1 += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    outfile.write(''.join([line.strip(), ',normal', '\\n']))\n",
    "                    count += 1\n",
    "            else:\n",
    "                #print(\"# of normal traffic: \", count)\n",
    "                break\n",
    "        print(\"# of normal traffic: \", count)\n",
    "    \n",
    "    #select blacklist traffic\n",
    "    with open(input_b_file) as b_infile:\n",
    "        count_b = 0\n",
    "        for line in b_infile:\n",
    "            if '2016-03-19 10:' in line:\n",
    "                break\n",
    "                \n",
    "            if count_b < threshold2:\n",
    "                if \"blacklist\" in line:\n",
    "                    outfile.write(''.join([line.strip(), ',abnormal', '\\n']))\n",
    "                    count_b += 1\n",
    "            else:\n",
    "                break\n",
    "        print(\"# of blacklist traffic: \", count_b)\n",
    "        \n",
    "    #select spam traffic\n",
    "    with open(input_sp_file) as b_infile:\n",
    "        count_b = 0\n",
    "        for line in b_infile:\n",
    "            if '2016-03-19 10:' in line:\n",
    "                break\n",
    "                \n",
    "            if count_b < threshold2:\n",
    "                if \"spam\" in line:\n",
    "                    outfile.write(''.join([line.strip(), ',abnormal', '\\n']))\n",
    "                    count_b += 1\n",
    "            else:\n",
    "                break\n",
    "        print(\"# of spam traffic: \", count_b)\n",
    "        \n",
    "    #select ssh scan traffic\n",
    "    with open(input_ssh_file) as b_infile:\n",
    "        count_b = 0\n",
    "        for line in b_infile:\n",
    "            if '2016-03-19 10:' in line:\n",
    "                break\n",
    "                \n",
    "            if count_b < threshold2:\n",
    "                if \"sshscan\" in line:\n",
    "                    outfile.write(''.join([line.strip(), ',abnormal', '\\n']))\n",
    "                    count_b += 1\n",
    "            else:\n",
    "                break\n",
    "        print(\"# of ssh scan traffic: \", count_b)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Done!\")\n",
    "print(\"# of blacklist (skipped) in the normal traffic: \", count1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal traffic:\n",
      "             DateTime\n",
      "2016-03-18  10           402909\n",
      "            11          3290391\n",
      "            12          3391740\n",
      "            13          3348730\n",
      "            14          3071384\n",
      "            15          2955956\n",
      "            16          2975228\n",
      "            17          3172810\n",
      "            18          3183890\n",
      "            19          3196576\n",
      "            20          2971959\n",
      "            21          2671506\n",
      "            22          2606446\n",
      "            23          2557217\n",
      "2016-03-19  0           2467561\n",
      "            1           2512908\n",
      "            2           2303256\n",
      "            3           2604419\n",
      "            4           2397619\n",
      "            5           2188603\n",
      "            6           2086704\n",
      "            7           2176140\n",
      "            8           2217629\n",
      "            9           2586101\n",
      "Name: Label, dtype: int64\n",
      "Abnormal traffic:\n",
      "             DateTime\n",
      "2016-03-18  10            21\n",
      "            11           567\n",
      "            12           348\n",
      "            13          1743\n",
      "            14           802\n",
      "            15           859\n",
      "            16           940\n",
      "            17          1511\n",
      "            18           813\n",
      "            19          2585\n",
      "            20          1219\n",
      "            21          4694\n",
      "            22          4941\n",
      "            23          1642\n",
      "2016-03-19  0           2731\n",
      "            1           1243\n",
      "            2            148\n",
      "            3            339\n",
      "            4            150\n",
      "            5            159\n",
      "            6            188\n",
      "            7            175\n",
      "            8            185\n",
      "            9            178\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "dtypes = {\n",
    "\t\"FlowDuration\" : \"float64\",\n",
    "    \"SrcIP\": \"category\",\n",
    "    \"DstIP\": \"category\",\n",
    "    \"SrcPort\": \"int32\",\n",
    "    \"DstPort\": \"int32\",\n",
    "    \"Protocol\": \"category\",\n",
    "    \"Flag\": \"category\",\n",
    "    \"ForwardingStatus\": \"int32\",\n",
    "    \"TypeofService\": \"int32\",\n",
    "    \"PacketExed\": \"int32\",\n",
    "    \"Bytes\": \"int32\",\n",
    "    \"TrafficType\": \"category\",\n",
    "    \"Label\": \"category\",\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"./UGRdata/parsed/selected_24h.csv\",\n",
    "    dtype=dtypes,\n",
    "    usecols=list(dtypes) + [\"DateTime\"],\n",
    "    parse_dates=[\"DateTime\"]\n",
    ").set_index(\"DateTime\")\n",
    "\n",
    "filter_ = df.index < '2016-03-19 10:00:00'\n",
    "\n",
    "#df[filter_]\n",
    "\n",
    "df_f = df[filter_]\n",
    "\n",
    "is_abnormal = df_f['Label'] == 'abnormal'\n",
    "is_normal = df_f['Label'] == 'normal'\n",
    "df_b = df_f[is_abnormal]\n",
    "df_n = df_f[is_normal]\n",
    "\n",
    "\n",
    "grouped_n = df_n.groupby([df_n.index.date, df_n.index.hour])\n",
    "print(\"Normal traffic:\\n\", grouped_n['Label'].count())\n",
    "\n",
    "grouped_b = df_b.groupby([df_b.index.date, df_b.index.hour])\n",
    "print(\"Abnormal traffic:\\n\", grouped_b['Label'].count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import socket, struct\n",
    "\n",
    "input_file = \"./UGRdata/parsed/selected_24h.csv\"\n",
    "output_file = \"./UGRdata/parsed/selected_24h_parsed.csv\"\n",
    "init_dt_str = '2016-03-18 00:00:00'\n",
    "\n",
    "def convert_int_ip(ipint):\n",
    "    #ipint=16909060\n",
    "    return socket.inet_ntoa(struct.pack('!L', ipint))\n",
    "    \n",
    "def convert_ip(ipstr):\n",
    "    if ipstr.strip == \"\":\n",
    "        return 0\n",
    "    return struct.unpack(\"!L\", socket.inet_aton(ipstr.strip()))[0]\n",
    "\n",
    "def convert_prot(pstr):\n",
    "    switcher = {\n",
    "        \"TCP\": 1,\n",
    "        \"UDP\": 2,\n",
    "        \"ICMP\": 3,\n",
    "        \"ESP\": 4,\n",
    "        \"IPIP\": 5,\n",
    "        \"GRE\": 6,\n",
    "    }\n",
    "    return (switcher.get(pstr, 0))\n",
    "\n",
    "def get_header():\n",
    "    return ['Label','Timestamp', 'FlowDuration', 'SrcIP', 'DstIP', 'SrcPort','DstPort','Protocol','ForwardingStatus','TypeofService','PacketExed', 'Bytes']\n",
    "\n",
    "\n",
    "with open(output_file, 'w') as outfile:\n",
    "    csv_writer = csv.writer(outfile, delimiter=',')\n",
    "    csv_writer.writerow(get_header())\n",
    "    with open(input_file) as csv_file:\n",
    "        init_dt = datetime.strptime(init_dt_str, '%Y-%m-%d %H:%M:%S')\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        \n",
    "\n",
    "        for row in csv_reader:\n",
    "            if len(row) == 0 or 'SrcIP' in row:\n",
    "                print('header')\n",
    "                continue\n",
    "\n",
    "            new_row = []\n",
    "            lab = row[13]\n",
    "            new_row.append(lab)\n",
    "\n",
    "            dt_str = row[0].strip()\n",
    "            dt_obj = datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S')\n",
    "            if dt_obj >= datetime.strptime('2016-03-19 10:00:00',  '%Y-%m-%d %H:%M:%S'):\n",
    "                continue\n",
    "\n",
    "            diff = dt_obj - init_dt\n",
    "            diff_sec = diff.seconds\n",
    "            new_row.append(diff_sec)\n",
    "            new_row.append(row[1])\n",
    "            new_row.append(convert_ip(row[2]))\n",
    "            new_row.append(convert_ip(row[3]))\n",
    "            new_row.append(row[4])\n",
    "            new_row.append(row[5])\n",
    "            new_row.append(convert_prot(row[6].strip()))\n",
    "            new_row.append(row[8])\n",
    "            new_row.append(row[9])\n",
    "            new_row.append(row[10])\n",
    "            new_row.append(row[11])\n",
    "            csv_writer.writerow(new_row)\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
